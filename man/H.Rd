% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/H.R
\name{H}
\alias{H}
\title{Shannon's Entropy \eqn{H(X)}}
\usage{
H(X)
}
\arguments{
\item{X}{a numeric probability vector \eqn{P(X)} for which
Shannon's Entropy \eqn{H(X)} shall be computed.}
}
\value{
a numeric value representing Shannon's Entropy in bit.
}
\description{
Compute the Shannon's Entropy \eqn{H(X) = - \sum P(X) * log2(P(X))} based on a
given probability vector \eqn{P(X)}.
}
\details{
This function might be useful to fastly compute Shannon's Entropy for any
given probability vector.
}
\examples{
# read a standard PhyloExpressionSet
data(PhyloExpressionSetExample)

# compute the Entropy based on the probability P(PS) of developmental stage 1
EntropyValue <- H(Probability(PhyloExpressionSetExample)[ , 1])

# or

# compute the phylotranscriptomics Entropy profile analogous to the 'Entopy' function
EntropyProfile <- apply(Probability(PhyloExpressionSetExample),2,H)

# and compare it with the 'Entropy' function
EntropyProfile2 <- Entropy(PhyloExpressionSetExample)
}
\author{
Hajk-Georg Drost
}
\references{
Shannon, Claude E. 1948. "A Mathematical Theory of
Communication". \emph{Bell System Technical Journal} \bold{27} (3): 379-423.
}
\seealso{
\code{\link{CE}}, \code{\link{KL}}, \code{\link{JSD}}, \code{\link{gJSD}}, \code{\link{Entropy}}
}

